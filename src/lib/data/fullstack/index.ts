import type { Challenge } from '../../types';

export const fullstackChallenges: Challenge[] = [
  {
    id: 'fs-001',
    category: 'fullstack',
    subcategory: 'auth-flows',
    title: 'Design an Authentication System',
    difficulty: 4,
    type: 'DESIGN',
    description: 'Design a complete authentication system for a web application. Cover registration, login, session management, password reset, and security considerations. Address token storage, refresh token rotation, and CSRF protection.',
    solution: 'Authentication System Design:\n\n1. Registration Flow:\n- Client sends email + password to POST /auth/register\n- Server validates input, checks for existing email\n- Password hashed with bcrypt (cost factor 12)\n- Store user record, send verification email with signed token\n- Return 201 with message "Check your email"\n\n2. Login Flow:\n- Client sends credentials to POST /auth/login\n- Server validates credentials, checks email verified\n- Generate access token (JWT, 15 min expiry) and refresh token (opaque, 7 day expiry)\n- Store refresh token hash in database (not the token itself)\n- Return access token in response body, refresh token in httpOnly secure cookie\n\n3. Token Strategy:\n- Access Token: Short-lived JWT (15 min). Contains userId, role. Sent in Authorization header.\n- Refresh Token: Long-lived opaque token. Stored in httpOnly, Secure, SameSite=Strict cookie. Used only to get new access tokens.\n- Token Rotation: Each refresh invalidates the old refresh token and issues a new one. If a reused token is detected, revoke all tokens for that user (stolen token detection).\n\n4. Session Management:\n- POST /auth/refresh — validates refresh token cookie, returns new access token + rotates refresh token\n- POST /auth/logout — invalidates refresh token in database, clears cookie\n- GET /auth/me — validates access token, returns user profile\n\n5. Password Reset:\n- POST /auth/forgot-password — generates signed reset token (1 hour expiry), sends email\n- POST /auth/reset-password — validates reset token, updates password, invalidates all refresh tokens\n\n6. Security Considerations:\n- CSRF: SameSite=Strict cookie + require custom header (X-Requested-With) for state-changing requests\n- Rate limiting on login (5 attempts per 15 min per IP)\n- Account lockout after 10 failed attempts\n- Password requirements: minimum 8 characters, check against breached password list\n- All tokens transmitted over HTTPS only\n- Audit log for security events (login, logout, password change, failed attempts)',
    solutionExplanation: 'This design demonstrates understanding of modern auth best practices. Key decisions: (1) Short-lived JWTs for access (stateless, fast verification) + long-lived refresh tokens for session persistence. (2) Refresh token rotation prevents token theft from going undetected. (3) httpOnly cookies for refresh tokens prevent XSS from stealing session tokens. (4) SameSite + custom header for CSRF protection. (5) Password hashing with bcrypt (not SHA256). (6) Rate limiting and lockout for brute force protection.',
    hints: ['Think about TWO types of tokens: short-lived access tokens (JWT, 15 min) for API access, and long-lived refresh tokens (opaque, stored server-side) for session persistence.', 'Where you store tokens matters for security. Access token in memory/localStorage (vulnerable to XSS). Refresh token in httpOnly cookie (protected from XSS, needs CSRF protection).'],
    tags: ['authentication', 'jwt', 'security', 'system-design', 'cookies'],
    estimatedMinutes: 20,
    conceptSections: [
      {
        title: 'Registration and Login Flow',
        keyTakeaway: 'Registration validates input, hashes passwords with bcrypt, and sends verification emails. Login validates credentials and issues two types of tokens with different lifetimes and purposes.',
        explanation: 'The registration flow is the entry point: validate input shape, check for existing emails, hash the password with bcrypt (cost factor 12 — never store plaintext or use fast hashes like SHA256), store the user record, and send a verification email with a signed token. The login flow authenticates credentials, checks email verification status, and issues both an access token and a refresh token. These two token types serve fundamentally different purposes and have different security characteristics, which is covered in the next section.',
        relatedPatterns: ['bcrypt', 'Email Verification', 'Input Validation', 'OWASP Authentication Guidelines'],
      },
      {
        title: 'Token Strategy: Access + Refresh',
        keyTakeaway: 'Use short-lived JWTs (15 min) for API access and long-lived opaque refresh tokens (7 days, httpOnly cookie) for session persistence. This combines the speed of stateless tokens with the security of server-side sessions.',
        explanation: 'Access tokens are JWTs — self-contained, signed tokens that can be verified without a database call. They are fast but cannot be revoked once issued, which is why they must be short-lived (15 minutes). Refresh tokens are opaque (random strings), stored server-side as hashed values, and placed in httpOnly Secure SameSite=Strict cookies. They last longer (7 days) and can be revoked by deleting the server-side record. The access token goes in the Authorization header; the refresh token stays in a cookie that JavaScript cannot access (XSS protection). This two-token architecture gives you the performance of stateless auth with the security control of server-side sessions.',
        relatedPatterns: ['JWT', 'OAuth 2.0 Refresh Tokens', 'httpOnly Cookies', 'Stateless Authentication'],
      },
      {
        title: 'Session Management and Token Rotation',
        keyTakeaway: 'Each refresh rotates both tokens and invalidates the old refresh token. Detecting reuse of an old token triggers revocation of ALL tokens for that user (stolen token detection).',
        explanation: 'Token rotation is a critical security mechanism. When a client uses their refresh token to get a new access token, the server also issues a new refresh token and invalidates the old one. If an attacker steals a refresh token and uses it after the legitimate user already refreshed, the server detects the reuse of an invalidated token and revokes ALL tokens for that user. This forces both the attacker and the legitimate user to re-authenticate, but it prevents silent ongoing compromise. The /auth/refresh endpoint validates the refresh token cookie, returns a new access token, and rotates the refresh token. The /auth/logout endpoint invalidates the refresh token and clears the cookie.',
        relatedPatterns: ['Token Rotation', 'Refresh Token Families', 'Session Revocation', 'Stolen Token Detection'],
      },
      {
        title: 'Password Reset Flow',
        keyTakeaway: 'Password reset uses a signed, time-limited token (1 hour) sent via email. After reset, ALL existing refresh tokens are invalidated to force re-authentication on all devices.',
        explanation: 'The forgot-password endpoint generates a cryptographically signed token with a 1-hour expiry and emails it as a link. The reset-password endpoint validates the token, updates the password hash, and — critically — invalidates ALL refresh tokens for that user. This ensures that if the password reset was triggered because an account was compromised, the attacker is immediately logged out of all devices. The token should be single-use (mark as used after consumption) to prevent replay attacks.',
        relatedPatterns: ['Signed Tokens', 'Time-Limited URLs', 'Session Invalidation', 'Account Recovery'],
      },
      {
        title: 'Security Hardening',
        keyTakeaway: 'Defense in depth: CSRF protection via SameSite cookies + custom headers, rate limiting on login (5 attempts/15 min), account lockout after 10 failures, and HTTPS-only token transmission.',
        explanation: 'Security is layered. CSRF protection uses SameSite=Strict on cookies (prevents cross-origin requests from including the cookie) combined with requiring a custom header like X-Requested-With (which cannot be set by cross-origin forms). Rate limiting prevents brute-force attacks: 5 failed attempts per 15 minutes per IP, with account lockout after 10 consecutive failures. Password requirements should include minimum length (8 characters) and checking against breached password lists (Have I Been Pwned API). All tokens must be transmitted over HTTPS only — set the Secure flag on cookies. Finally, maintain an audit log of all security events (logins, logouts, failed attempts, password changes) for incident response.',
        relatedPatterns: ['CSRF Protection', 'Rate Limiting', 'Brute Force Prevention', 'OWASP Top 10', 'Defense in Depth'],
      },
    ],
  },
  {
    id: 'fs-002',
    category: 'fullstack',
    subcategory: 'realtime',
    title: 'Real-time Chat Architecture',
    difficulty: 4,
    type: 'DESIGN',
    description: 'Design the architecture for a real-time chat application supporting 1:1 and group messages. Cover the technology choices (WebSockets vs SSE), message delivery guarantees, online status, typing indicators, and how to handle users on multiple devices.',
    solution: 'Architecture Overview:\n\nTechnology: WebSockets (bidirectional needed for typing indicators, presence, and sending messages).\n\nComponents:\n1. WebSocket Gateway: Handles connections, authentication, message routing\n2. Message Service: Persists messages, handles delivery status\n3. Presence Service: Tracks online/offline status\n4. Notification Service: Push notifications for offline users\n5. Message Queue (Redis Pub/Sub): Routes messages between gateway instances\n\nConnection Flow:\n- Client connects via WebSocket with JWT token\n- Gateway validates token, registers connection (userId -> connectionId mapping)\n- User may have multiple connections (phone + laptop) — store as a set\n- On disconnect, wait 30 seconds before marking offline (handles page refreshes)\n\nMessage Flow:\n1. Sender sends message via WebSocket to Gateway\n2. Gateway publishes to Message Service (persist) and Redis Pub/Sub (route)\n3. All Gateway instances subscribed to Redis check if recipient is connected\n4. If connected: deliver via WebSocket, mark as "delivered"\n5. If not connected: store in pending queue, send push notification\n6. When recipient connects: deliver pending messages\n\nMessage Delivery Guarantees:\n- Sent: Server received and persisted message\n- Delivered: Recipient device received message (WebSocket ACK)\n- Read: Recipient opened the conversation (explicit read receipt)\n- Use message IDs for idempotency (prevent duplicates on reconnection)\n\nTyping Indicators:\n- Client sends "typing" event with conversation ID\n- Gateway broadcasts to other participants via Redis Pub/Sub\n- Auto-expire after 3 seconds (client stops sending if user stops typing)\n- Do NOT persist typing events — ephemeral only\n\nOnline Presence:\n- Maintained in Redis (SETEX userId online TTL 60)\n- Client sends heartbeat every 30 seconds to refresh TTL\n- On disconnect, TTL expires after 60 seconds\n- Friends/contacts query presence from Redis\n\nScaling:\n- Multiple WebSocket Gateway instances behind a load balancer (sticky sessions or Redis routing)\n- Redis Pub/Sub for cross-instance message routing\n- Database sharding by conversation ID for message storage\n- CDN for media attachments',
    solutionExplanation: 'This design handles the core challenges of real-time chat: reliable delivery, multi-device support, presence, and scaling. Key decisions: WebSockets over SSE (bidirectional needed), Redis Pub/Sub for cross-instance routing (essential for horizontal scaling), separate delivery statuses (sent/delivered/read), and heartbeat-based presence with TTL expiry. The 30-second disconnect delay prevents false offline status during page navigation.',
    hints: ['Think about multi-device: a user logged in on phone and laptop must receive messages on both. This means one userId maps to multiple WebSocket connections.', 'Horizontal scaling is the hard part. If User A is connected to Gateway 1 and User B to Gateway 2, how does a message from A reach B? You need a message bus (Redis Pub/Sub) between gateway instances.'],
    tags: ['real-time', 'websocket', 'chat', 'system-design', 'redis', 'pub-sub'],
    estimatedMinutes: 20,
  },
  {
    id: 'fs-003',
    category: 'fullstack',
    subcategory: 'file-uploads',
    title: 'File Upload Pipeline Design',
    difficulty: 3,
    type: 'DESIGN',
    description: 'Design a file upload system for a web application that supports large files (up to 100MB), progress tracking, resumable uploads, and image processing (thumbnail generation). Cover frontend and backend architecture.',
    solution: 'Architecture:\n\nFrontend:\n- Chunked upload: Split file into 5MB chunks using File.slice()\n- Upload each chunk with chunk index and upload ID\n- Track progress per chunk, calculate overall progress\n- On network failure, resume from the last successful chunk\n- Show progress bar with percentage and speed\n\nUpload Flow:\n1. POST /uploads/init — Client sends filename, size, MIME type. Server creates upload record, returns uploadId\n2. PUT /uploads/:uploadId/chunks/:chunkIndex — Upload each chunk with Content-Type: application/octet-stream\n3. POST /uploads/:uploadId/complete — Client signals all chunks sent. Server assembles file\n4. Server returns presigned URL or file ID\n\nBackend Architecture:\n- Upload Service: Handles chunk reception, stores chunks temporarily\n- Assembly Service: Combines chunks into final file after completion signal\n- Processing Queue: Background job for image processing (thumbnail, resize)\n- Storage: S3 for final files, temporary local/S3 storage for chunks\n\nChunk Storage Strategy:\n- Store chunks in S3 with key pattern: uploads/{uploadId}/chunks/{index}\n- On complete: use S3 multipart upload API to assemble\n- Clean up incomplete uploads after 24 hours (S3 lifecycle policy)\n\nImage Processing:\n- After assembly, push job to processing queue (Bull/SQS)\n- Worker generates thumbnails (150x150, 300x300, 600x600)\n- Store processed images alongside original\n- Update file record with processing status and URLs\n\nSecurity:\n- Validate file type on both client and server (check magic bytes, not just extension)\n- Virus scan before making file available\n- Size limits enforced per chunk and total\n- Signed upload URLs prevent unauthorized uploads\n- Rate limiting on upload endpoints',
    solutionExplanation: 'Chunked uploads solve large file handling: they enable progress tracking, resumability (restart from last chunk), and avoid server memory issues (stream chunks directly to storage). S3 multipart upload is the standard approach for assembly. Background processing for images prevents upload requests from timing out. The init/chunks/complete three-phase protocol gives the server control over the upload lifecycle.',
    hints: ['Think about what happens when the network drops mid-upload. Chunked uploads let you resume from the last successful chunk instead of restarting.', 'Never process files (thumbnails, virus scan) synchronously in the upload request. Use a background job queue.'],
    tags: ['file-upload', 'chunked-upload', 's3', 'image-processing', 'system-design'],
    estimatedMinutes: 15,
  },
  {
    id: 'fs-004',
    category: 'fullstack',
    subcategory: 'notifications',
    title: 'Design a Notification System',
    difficulty: 4,
    type: 'DESIGN',
    description: 'Design a notification system that supports in-app notifications, email, and push notifications. Cover the architecture for creating, storing, delivering, and managing notifications. Handle user preferences and notification batching.',
    solution: 'Architecture:\n\nComponents:\n1. Notification Producer: Any service that triggers notifications (order service, user service, etc.)\n2. Notification Service: Central service that processes, routes, and delivers notifications\n3. Template Service: Manages notification templates per channel\n4. Preference Service: Stores user notification preferences\n5. Delivery Channels: In-app, Email (SendGrid/SES), Push (FCM/APNs)\n6. Message Queue: Decouples production from delivery\n\nFlow:\n1. Producer publishes event to queue: { type: "order_shipped", userId: "123", data: { orderId, trackingUrl } }\n2. Notification Service consumes event:\n   a. Check user preferences (does user want this notification type? Which channels?)\n   b. Render template for each enabled channel\n   c. In-app: Store in notifications table, push via WebSocket if connected\n   d. Email: Check batching rules, queue for delivery\n   e. Push: Send via FCM/APNs\n3. Track delivery status per channel\n\nData Model:\nnotifications: id, userId, type, title, body, data (JSON), channel, status (pending/delivered/read), createdAt\npreferences: userId, notificationType, channels (in_app, email, push), frequency (instant, daily_digest, weekly_digest)\n\nIn-App Delivery:\n- Store in database, query on page load\n- If user has active WebSocket connection, push immediately\n- Unread count badge updated via WebSocket or polling\n- Mark as read: PUT /notifications/:id/read\n- Mark all as read: PUT /notifications/read-all\n\nEmail Batching:\n- Instant: Send immediately (password reset, security alerts)\n- Daily digest: Aggregate notifications, send at user preferred time\n- Weekly digest: Weekly summary email\n- Use a scheduled job to process batched notifications\n\nPush Notifications:\n- Store device tokens per user (users may have multiple devices)\n- Use FCM for Android/web, APNs for iOS\n- Handle token expiry and unregistration\n\nScaling:\n- Message queue ensures notifications are not lost during high load\n- Separate workers per channel (email worker, push worker)\n- Rate limiting per user to prevent notification spam\n- Exponential backoff for failed deliveries',
    solutionExplanation: 'A notification system is a classic distributed system design problem. Key design decisions: (1) Event-driven architecture decouples producers from delivery, (2) User preferences per notification type give users control, (3) Multi-channel delivery requires channel-specific handling, (4) Batching reduces notification fatigue, (5) WebSocket for real-time in-app delivery, (6) Message queue for reliability and scaling.',
    hints: ['Decouple notification production from delivery. Producers should not know or care about delivery channels. They emit events; the notification service handles routing.', 'User preferences are critical. Not every notification should go to every channel. Let users control what they receive and how.'],
    tags: ['notifications', 'system-design', 'event-driven', 'multi-channel', 'message-queue'],
    estimatedMinutes: 18,
  },
  {
    id: 'fs-005',
    category: 'fullstack',
    subcategory: 'system-design',
    title: 'URL Shortener System Design',
    difficulty: 3,
    type: 'DESIGN',
    description: 'Design a URL shortener service like bit.ly. Cover the shortening algorithm, redirect flow, analytics tracking, and scaling considerations. The service should handle 100M URLs and 1B redirects per month.',
    solution: 'Core Requirements:\n- Shorten URL: POST /api/shorten { url } -> { shortUrl }\n- Redirect: GET /:code -> 301/302 redirect to original URL\n- Analytics: Track clicks per short URL\n\nShortening Algorithm:\nApproach: Base62 encoding of an auto-incrementing ID.\n1. Insert original URL into database, get auto-increment ID\n2. Encode ID to Base62 (a-z, A-Z, 0-9) -> 7 characters supports 3.5 trillion URLs\n3. Example: ID 12345 -> Base62 "dnh"\n\nWhy not hashing (MD5/SHA)?\n- Collisions require checking and retrying\n- Fixed output length may be longer than needed\n- Base62 of sequential ID is guaranteed unique, shorter, and no collision check needed\n\nRedirect Flow:\n1. User requests GET /abc123\n2. Check Redis cache for code -> URL mapping\n3. If cache miss, query database\n4. Return 301 (permanent, browser caches) or 302 (temporary, always hits server)\n5. For analytics, use 302 so every click hits the server\n6. Log click event asynchronously (write to Kafka/queue, not synchronously)\n\nData Model:\nurls: id (bigint), code (varchar 7 indexed), original_url (text), user_id, created_at, expires_at\nclicks: id, url_id, timestamp, ip, user_agent, referrer, country\n\nAnalytics:\n- Click events written to message queue (Kafka) for async processing\n- Aggregate in batch: clicks per hour/day, top referrers, geographic distribution\n- Pre-compute aggregates, do not query raw click table for dashboards\n\nScaling for 1B redirects/month:\n- ~400 redirects/second average, ~2000 peak\n- Redis cache for hot URLs (LRU eviction): handles most reads\n- Read replicas for database: handles cache misses\n- Kafka for click event ingestion: handles write throughput\n- CDN for redirect (optional): cache 301 responses at edge\n\nAdditional Features:\n- Custom short codes: allow users to choose their own code (check uniqueness)\n- Expiration: TTL on URLs, background job to clean expired\n- Rate limiting: prevent abuse (100 URLs per hour per IP)',
    solutionExplanation: 'URL shortener is a classic system design interview question. The key decisions are: (1) Base62 encoding of auto-increment ID is simpler and collision-free vs hashing, (2) 301 vs 302 redirect depends on analytics needs, (3) Redis cache is essential for read-heavy workload, (4) Async analytics processing prevents redirect latency, (5) The math matters: 7 Base62 characters = 62^7 = 3.5 trillion possible URLs.',
    hints: ['The shortening algorithm choice matters. Base62 of sequential ID is simpler and guaranteed unique. Hashing (MD5) has collisions.', 'For analytics, do NOT process clicks synchronously in the redirect path. Log to a queue and process asynchronously.'],
    tags: ['url-shortener', 'system-design', 'scaling', 'caching', 'base62'],
    estimatedMinutes: 15,
  },
  {
    id: 'fs-006',
    category: 'fullstack',
    subcategory: 'realtime',
    title: 'WebSocket vs SSE vs Polling',
    difficulty: 3,
    type: 'EXPLAIN',
    description: 'Compare three approaches for real-time communication: WebSockets, Server-Sent Events (SSE), and Long Polling. Discuss the trade-offs, connection overhead, browser support, and when each is appropriate.',
    solution: 'Long Polling:\nMechanism: Client sends request, server holds it open until data is available (or timeout), responds, client immediately sends another request.\nPros: Works everywhere (standard HTTP), no special server support, works through proxies/firewalls.\nCons: High overhead (new HTTP request per message), latency between messages, server holds many open connections.\nBest for: Simple real-time needs, legacy browser support, environments where WebSocket is blocked.\n\nServer-Sent Events (SSE):\nMechanism: Client opens a persistent HTTP connection. Server pushes events as text/event-stream. Unidirectional (server to client only).\nPros: Built on standard HTTP (works through proxies), automatic reconnection built-in, event ID for resuming after disconnect, simple API (EventSource), lightweight.\nCons: Unidirectional only (client cannot send via the same connection), limited to ~6 connections per domain in HTTP/1.1, text-only (no binary).\nBest for: Live feeds, stock tickers, notifications, dashboards, any server-to-client push. Surprisingly underused.\n\nWebSockets:\nMechanism: Upgrades HTTP connection to full-duplex TCP socket. Both sides can send messages at any time.\nPros: True bidirectional, low overhead per message (no HTTP headers), supports binary data, lowest latency.\nCons: Not standard HTTP (may be blocked by proxies/firewalls), no automatic reconnection (must implement), harder to load balance (sticky sessions), more complex server infrastructure.\nBest for: Chat, multiplayer games, collaborative editing, any use case requiring bidirectional real-time communication.\n\nDecision Framework:\n1. Does the client need to send real-time data to the server? -> WebSocket\n2. Is it server-to-client only? -> SSE (simpler than WebSocket)\n3. Need it to work in restricted network environments? -> Long Polling (fallback)\n4. Many concurrent connections with minimal messages? -> SSE (lighter than WebSocket)\n\nCommon mistake: Using WebSockets when SSE would suffice. If you only need server-to-client push (notifications, live updates, dashboards), SSE is simpler, has automatic reconnection, and works through HTTP infrastructure.',
    solutionExplanation: 'This tests practical knowledge of real-time communication. The key insight is that SSE is often the right answer and is underused — many developers default to WebSockets when they only need server-to-client push. WebSockets are overkill for unidirectional use cases and add infrastructure complexity (sticky sessions, connection management). The decision framework should be based on directionality first.',
    hints: ['The most common mistake is defaulting to WebSockets. Ask first: does the CLIENT need to send data in real-time? If only the server pushes, SSE is simpler.', 'Consider infrastructure implications. WebSockets need sticky sessions for load balancing. SSE works with standard HTTP load balancers.'],
    tags: ['real-time', 'websocket', 'sse', 'polling', 'trade-offs'],
    estimatedMinutes: 10,
  }
];
