import type { Challenge } from '../../types';

export const backendChallenges: Challenge[] = [
  {
    id: 'be-001',
    category: 'backend',
    subcategory: 'api-design',
    title: 'RESTful Route Design',
    difficulty: 2,
    type: 'CODE',
    description: 'Design Express.js routes for a blog API following RESTful conventions. Include proper HTTP methods (GET, POST, PUT, DELETE), meaningful resource URIs, and correct HTTP status codes for each operation. Handle both individual resources and collections.',
    starterCode: `const express = require('express');\nconst router = express.Router();\n\n// TODO: Implement the following REST endpoints for a blog:\n// - List all posts\n// - Get a single post\n// - Create a new post\n// - Update an existing post\n// - Delete a post\n// - List comments for a post\n// - Add a comment to a post\n\n// Your code here\n\nmodule.exports = router;`,
    solution: `const express = require('express');\nconst router = express.Router();\n\n// List all posts - GET /posts\nrouter.get('/posts', async (req, res) => {\n  const { page = 1, limit = 10, sort = 'createdAt' } = req.query;\n  const posts = await PostService.findAll({ page, limit, sort });\n  res.status(200).json({ data: posts.items, meta: { page, limit, total: posts.total } });\n});\n\n// Get single post - GET /posts/:id\nrouter.get('/posts/:id', async (req, res) => {\n  const post = await PostService.findById(req.params.id);\n  if (!post) return res.status(404).json({ error: 'Post not found' });\n  res.status(200).json({ data: post });\n});\n\n// Create post - POST /posts\nrouter.post('/posts', async (req, res) => {\n  const post = await PostService.create(req.body);\n  res.status(201).json({ data: post });\n});\n\n// Update post - PUT /posts/:id\nrouter.put('/posts/:id', async (req, res) => {\n  const post = await PostService.update(req.params.id, req.body);\n  if (!post) return res.status(404).json({ error: 'Post not found' });\n  res.status(200).json({ data: post });\n});\n\n// Delete post - DELETE /posts/:id\nrouter.delete('/posts/:id', async (req, res) => {\n  const deleted = await PostService.delete(req.params.id);\n  if (!deleted) return res.status(404).json({ error: 'Post not found' });\n  res.status(204).send();\n});\n\n// List comments for a post - GET /posts/:id/comments\nrouter.get('/posts/:id/comments', async (req, res) => {\n  const comments = await CommentService.findByPostId(req.params.id);\n  res.status(200).json({ data: comments });\n});\n\n// Add comment to post - POST /posts/:id/comments\nrouter.post('/posts/:id/comments', async (req, res) => {\n  const comment = await CommentService.create(req.params.id, req.body);\n  res.status(201).json({ data: comment });\n});\n\nmodule.exports = router;`,
    solutionExplanation: 'RESTful design maps CRUD operations to HTTP methods: GET for reads, POST for creates, PUT for full updates (PATCH for partial), DELETE for removal. Resources are nouns (posts, comments), not verbs. Nested resources like comments belong under their parent: /posts/:id/comments. Status codes communicate results: 200 for success, 201 for created, 204 for no-content (delete), 404 for not found. Consistent response envelope ({data, meta}) makes the API predictable for consumers.',
    hints: ['Map CRUD to HTTP methods: Create=POST, Read=GET, Update=PUT, Delete=DELETE. Use nouns for resources.', 'Nested resources (comments on a post) use the pattern: /posts/:postId/comments. Use 201 for successful creation, 204 for successful deletion.'],
    testCases: [
      { input: 'GET /posts', expectedOutput: '200 with array of posts', description: 'List posts returns 200' },
      { input: 'POST /posts with body', expectedOutput: '201 with created post', description: 'Create returns 201' },
      { input: 'DELETE /posts/:id', expectedOutput: '204 no content', description: 'Delete returns 204' }
    ],
    tags: ['express', 'rest', 'api-design', 'http-methods', 'routing'],
    estimatedMinutes: 15,
  },
  {
    id: 'be-002',
    category: 'backend',
    subcategory: 'api-design',
    title: 'API Versioning Strategies',
    difficulty: 3,
    type: 'EXPLAIN',
    description: 'Compare and contrast three main API versioning strategies: URL path versioning (/api/v1/users), header versioning (Accept: application/vnd.api+json;version=1), and query parameter versioning (/api/users?version=1). Discuss when each is appropriate, their trade-offs, and which you would recommend for a new production API.',
    solution: 'URL Path Versioning (/api/v1/users): Most common and visible. Pros: explicit, cacheable, easy to route, easy to document. Cons: URL pollution, harder to sunset versions, couples version to URI. Best for: public APIs where clarity matters most.\n\nHeader Versioning (Accept header or custom X-API-Version): Pros: clean URLs, content negotiation aligns with HTTP semantics, can version independently of resource structure. Cons: harder to test (need tools to set headers), less discoverable, more complex routing. Best for: internal APIs, APIs where URL cleanliness is critical.\n\nQuery Parameter Versioning (?version=1): Pros: easy to add, works in browsers, simple to implement. Cons: easy to forget, optional nature causes ambiguity, pollutes query namespace. Best for: simple APIs, transitional versioning.\n\nRecommendation: For most production APIs, URL path versioning is the best default. It is the most explicit, easiest to document, and most widely understood. The minor URL pollution is a worthwhile trade-off for clarity. However, only create a new version when you have breaking changes. Non-breaking additions (new fields, new optional parameters) should be additive within the same version. Maintain at most 2-3 active versions and provide clear deprecation timelines.',
    solutionExplanation: 'This tests understanding of API design principles beyond just implementation. Senior engineers evaluate versioning as a contract and communication mechanism, not just a technical detail. The key insight is that versioning strategy affects documentation, caching, routing complexity, client migration, and discoverability. Strong answers discuss when NOT to version (additive changes are not breaking changes) and sunset strategies.',
    hints: ['Think about who consumes the API. Public APIs need maximum discoverability. Internal APIs can use less obvious mechanisms.', 'Consider the operational implications: how do you route requests to different version handlers? How do you cache responses? How do you document multiple versions?'],
    tags: ['api-design', 'versioning', 'rest', 'architecture'],
    estimatedMinutes: 10,
  },
  {
    id: 'be-003',
    category: 'backend',
    subcategory: 'architecture-patterns',
    title: 'Implement Repository Pattern',
    difficulty: 4,
    type: 'CODE',
    description: 'Implement a repository pattern in TypeScript that abstracts database access for a User entity. Create an interface for the repository, a concrete implementation, and demonstrate dependency inversion by injecting the repository into a service. The repository should support CRUD operations and filtering.',
    starterCode: `// TODO: Define IUserRepository interface with:\n// - findById(id: string): Promise<User | null>\n// - findAll(filter?: UserFilter): Promise<User[]>\n// - create(data: CreateUserDTO): Promise<User>\n// - update(id: string, data: UpdateUserDTO): Promise<User | null>\n// - delete(id: string): Promise<boolean>\n\n// TODO: Implement UserRepository class\n// TODO: Implement UserService that depends on IUserRepository`,
    solution: `interface User {\n  id: string;\n  email: string;\n  name: string;\n  role: 'admin' | 'user';\n  createdAt: Date;\n}\n\ninterface UserFilter {\n  role?: string;\n  search?: string;\n  limit?: number;\n  offset?: number;\n}\n\ninterface CreateUserDTO {\n  email: string;\n  name: string;\n  role?: 'admin' | 'user';\n}\n\ntype UpdateUserDTO = Partial<CreateUserDTO>;\n\n// Repository Interface (port)\ninterface IUserRepository {\n  findById(id: string): Promise<User | null>;\n  findAll(filter?: UserFilter): Promise<User[]>;\n  create(data: CreateUserDTO): Promise<User>;\n  update(id: string, data: UpdateUserDTO): Promise<User | null>;\n  delete(id: string): Promise<boolean>;\n}\n\n// Concrete Implementation (adapter)\nclass PostgresUserRepository implements IUserRepository {\n  constructor(private db: any) {}\n\n  async findById(id: string): Promise<User | null> {\n    const row = await this.db.query('SELECT * FROM users WHERE id = $1', [id]);\n    return row.rows[0] || null;\n  }\n\n  async findAll(filter?: UserFilter): Promise<User[]> {\n    let query = 'SELECT * FROM users WHERE 1=1';\n    const params: any[] = [];\n    if (filter?.role) { params.push(filter.role); query += \` AND role = $\${params.length}\`; }\n    if (filter?.search) { params.push(\`%\${filter.search}%\`); query += \` AND name ILIKE $\${params.length}\`; }\n    if (filter?.limit) { params.push(filter.limit); query += \` LIMIT $\${params.length}\`; }\n    if (filter?.offset) { params.push(filter.offset); query += \` OFFSET $\${params.length}\`; }\n    const result = await this.db.query(query, params);\n    return result.rows;\n  }\n\n  async create(data: CreateUserDTO): Promise<User> {\n    const result = await this.db.query(\n      'INSERT INTO users (email, name, role) VALUES ($1, $2, $3) RETURNING *',\n      [data.email, data.name, data.role || 'user']\n    );\n    return result.rows[0];\n  }\n\n  async update(id: string, data: UpdateUserDTO): Promise<User | null> {\n    const fields = Object.entries(data).filter(([_, v]) => v !== undefined);\n    if (fields.length === 0) return this.findById(id);\n    const sets = fields.map(([k], i) => \`\${k} = $\${i + 2}\`);\n    const values = fields.map(([_, v]) => v);\n    const result = await this.db.query(\n      \`UPDATE users SET \${sets.join(', ')} WHERE id = $1 RETURNING *\`,\n      [id, ...values]\n    );\n    return result.rows[0] || null;\n  }\n\n  async delete(id: string): Promise<boolean> {\n    const result = await this.db.query('DELETE FROM users WHERE id = $1', [id]);\n    return result.rowCount > 0;\n  }\n}\n\n// Service depends on interface, not implementation\nclass UserService {\n  constructor(private userRepo: IUserRepository) {}\n\n  async getUserById(id: string): Promise<User> {\n    const user = await this.userRepo.findById(id);\n    if (!user) throw new Error('User not found');\n    return user;\n  }\n\n  async createUser(data: CreateUserDTO): Promise<User> {\n    const existing = await this.userRepo.findAll({ search: data.email });\n    if (existing.length > 0) throw new Error('Email already exists');\n    return this.userRepo.create(data);\n  }\n}\n\n// Dependency injection\nconst db = getDBConnection();\nconst userRepo = new PostgresUserRepository(db);\nconst userService = new UserService(userRepo);`,
    solutionExplanation: 'The repository pattern creates an abstraction layer between business logic and data access. The interface (IUserRepository) defines the contract — what operations are available. The concrete class (PostgresUserRepository) implements database-specific logic. The service (UserService) depends only on the interface, not the implementation. This enables: swapping databases without changing business logic, unit testing services with mock repositories, and clear separation of concerns. This is dependency inversion (D in SOLID) — high-level modules depend on abstractions, not details.',
    hints: ['Define the interface first — it represents the contract. The service should depend on this interface, not on any concrete class.', 'The repository handles ALL database-specific code. The service should never contain SQL or database driver calls.'],
    testCases: [
      { input: 'userService.getUserById("123")', expectedOutput: 'User object or throws "User not found"', description: 'Service delegates to repository' },
      { input: 'new UserService(mockRepo) with mock', expectedOutput: 'Service works with any IUserRepository implementation', description: 'Dependency inversion works' },
      { input: 'userService.createUser with existing email', expectedOutput: 'Throws "Email already exists"', description: 'Business logic in service layer' }
    ],
    tags: ['repository-pattern', 'dependency-inversion', 'SOLID', 'architecture', 'typescript'],
    estimatedMinutes: 20,
  },
  {
    id: 'be-004',
    category: 'backend',
    subcategory: 'auth-security',
    title: 'JWT Authentication Middleware',
    difficulty: 3,
    type: 'CODE',
    description: 'Implement Express middleware for JWT-based authentication. The middleware should extract the token from the Authorization header (Bearer scheme), verify it, attach the decoded user payload to the request object, and handle various error cases (missing token, expired token, invalid token) with appropriate HTTP status codes and error messages.',
    starterCode: `const jwt = require('jsonwebtoken');\n\n// TODO: Implement authentication middleware\n// - Extract token from Authorization: Bearer <token>\n// - Verify token using JWT_SECRET\n// - Attach decoded payload to req.user\n// - Handle errors: missing token (401), invalid token (401), expired token (401)\n\nfunction authMiddleware(req, res, next) {\n  // Your implementation here\n}\n\n// TODO: Implement role-based authorization middleware\nfunction authorize(...roles) {\n  // Your implementation here\n}\n\nmodule.exports = { authMiddleware, authorize };`,
    solution: `const jwt = require('jsonwebtoken');\n\nconst JWT_SECRET = process.env.JWT_SECRET;\n\nfunction authMiddleware(req, res, next) {\n  const authHeader = req.headers.authorization;\n\n  if (!authHeader) {\n    return res.status(401).json({ error: 'Authorization header is required' });\n  }\n\n  // Check Bearer scheme\n  const parts = authHeader.split(' ');\n  if (parts.length !== 2 || parts[0] !== 'Bearer') {\n    return res.status(401).json({ error: 'Authorization format: Bearer <token>' });\n  }\n\n  const token = parts[1];\n\n  try {\n    const decoded = jwt.verify(token, JWT_SECRET);\n    req.user = decoded;\n    next();\n  } catch (err) {\n    if (err.name === 'TokenExpiredError') {\n      return res.status(401).json({ error: 'Token has expired' });\n    }\n    if (err.name === 'JsonWebTokenError') {\n      return res.status(401).json({ error: 'Invalid token' });\n    }\n    return res.status(401).json({ error: 'Authentication failed' });\n  }\n}\n\nfunction authorize(...roles) {\n  return (req, res, next) => {\n    if (!req.user) {\n      return res.status(401).json({ error: 'Not authenticated' });\n    }\n    if (!roles.includes(req.user.role)) {\n      return res.status(403).json({ error: 'Insufficient permissions' });\n    }\n    next();\n  };\n}\n\nmodule.exports = { authMiddleware, authorize };`,
    solutionExplanation: 'JWT authentication middleware follows a clear pattern: extract, verify, attach, continue. The token is extracted from the Authorization header using the Bearer scheme (RFC 6750). jwt.verify() checks both signature validity and expiration. Different error types (TokenExpiredError, JsonWebTokenError) map to descriptive error messages. The middleware attaches the decoded payload to req.user for downstream handlers. The authorize function is a higher-order middleware that checks the role from the decoded token. 401 means "not authenticated" while 403 means "authenticated but not authorized".',
    hints: ['Split the Authorization header by space. The format is "Bearer <token>". Validate both parts exist.', 'jwt.verify() throws different error types: TokenExpiredError for expired tokens, JsonWebTokenError for malformed/invalid tokens. Handle each case.'],
    testCases: [
      { input: 'Request with no Authorization header', expectedOutput: '401 with "Authorization header is required"', description: 'Missing header returns 401' },
      { input: 'Request with valid Bearer token', expectedOutput: '200, req.user is set', description: 'Valid token passes through' },
      { input: 'Request with expired token', expectedOutput: '401 with "Token has expired"', description: 'Expired token returns 401' }
    ],
    tags: ['jwt', 'authentication', 'middleware', 'express', 'security'],
    estimatedMinutes: 15,
  },
  {
    id: 'be-005',
    category: 'backend',
    subcategory: 'api-design',
    title: 'Cursor-Based Pagination',
    difficulty: 3,
    type: 'CODE',
    description: 'Implement cursor-based pagination for a REST API endpoint. Unlike offset-based pagination (page=2&limit=10), cursor-based pagination uses an opaque cursor pointing to the last item. This avoids the "shifting window" problem where items are missed or duplicated when data changes between page requests.',
    starterCode: `// TODO: Implement cursor-based pagination\n// Endpoint: GET /api/posts?cursor=<base64_cursor>&limit=10\n// Response: { data: [...], meta: { nextCursor, hasMore } }\n// Cursor should encode the sort field value of the last item`,
    solution: `function encodeCursor(id, sortValue) {\n  return Buffer.from(JSON.stringify({ id, sortValue })).toString('base64');\n}\n\nfunction decodeCursor(cursor) {\n  try {\n    return JSON.parse(Buffer.from(cursor, 'base64').toString('utf8'));\n  } catch {\n    throw new Error('Invalid cursor');\n  }\n}\n\nasync function getPaginatedPosts(req, res) {\n  const limit = Math.min(parseInt(req.query.limit) || 10, 100);\n  const cursor = req.query.cursor;\n  const sortField = 'createdAt';\n  const sortDir = 'DESC';\n\n  let query = 'SELECT * FROM posts';\n  const params = [];\n\n  if (cursor) {\n    const decoded = decodeCursor(cursor);\n    params.push(decoded.sortValue, decoded.id);\n    query += \` WHERE (\${sortField}, id) < ($1, $2)\`;\n  }\n\n  query += \` ORDER BY \${sortField} \${sortDir}, id \${sortDir}\`;\n  params.push(limit + 1); // Fetch one extra to check hasMore\n  query += \` LIMIT $\${params.length}\`;\n\n  const result = await db.query(query, params);\n  const items = result.rows;\n  const hasMore = items.length > limit;\n  const data = hasMore ? items.slice(0, limit) : items;\n\n  const lastItem = data[data.length - 1];\n  const nextCursor = hasMore && lastItem\n    ? encodeCursor(lastItem.id, lastItem[sortField])\n    : null;\n\n  res.json({\n    data,\n    meta: { nextCursor, hasMore, limit },\n  });\n}`,
    solutionExplanation: 'Cursor-based pagination encodes the last seen items sort value into a base64 cursor. The next query fetches items "after" that cursor using a WHERE clause comparison. The trick of fetching limit+1 items determines hasMore without an extra COUNT query. This approach is stable under concurrent inserts/deletes (no shifted windows), performs consistently regardless of page depth (unlike OFFSET which scans and discards rows), and works naturally with real-time data. The cursor is opaque to clients — they just pass it back to get the next page.',
    hints: ['Encode the cursor as base64 JSON containing the sort field value and id of the last item. Use tuple comparison (sortField, id) < ($1, $2) for stable ordering.', 'Fetch limit + 1 items. If you get more than limit, there are more pages. Return only limit items to the client.'],
    testCases: [
      { input: 'GET /posts?limit=2 (3 posts exist)', expectedOutput: '{ data: [post1, post2], meta: { nextCursor: "...", hasMore: true } }', description: 'First page with more data' },
      { input: 'GET /posts?cursor=<cursor>&limit=2', expectedOutput: '{ data: [post3], meta: { nextCursor: null, hasMore: false } }', description: 'Last page' },
      { input: 'GET /posts?cursor=invalid', expectedOutput: '400 Invalid cursor', description: 'Invalid cursor handled' }
    ],
    tags: ['pagination', 'cursor', 'api-design', 'database', 'performance'],
    estimatedMinutes: 15,
  },
  {
    id: 'be-006',
    category: 'backend',
    subcategory: 'api-design',
    title: 'Express Error Handler',
    difficulty: 3,
    type: 'CODE',
    description: 'Implement centralized error handling middleware for an Express API. Create a custom error class hierarchy and an error handler that returns consistent JSON error responses with appropriate status codes. Handle both operational errors (expected) and programming errors (unexpected).',
    starterCode: `// TODO: Create AppError base class\n// TODO: Create specific error classes (NotFoundError, ValidationError, AuthError)\n// TODO: Create errorHandler middleware\n// TODO: Create asyncHandler wrapper`,
    solution: `class AppError extends Error {\n  constructor(message, statusCode, code) {\n    super(message);\n    this.statusCode = statusCode;\n    this.code = code;\n    this.isOperational = true;\n    Error.captureStackTrace(this, this.constructor);\n  }\n}\n\nclass NotFoundError extends AppError {\n  constructor(resource = 'Resource') {\n    super(\`\${resource} not found\`, 404, 'NOT_FOUND');\n  }\n}\n\nclass ValidationError extends AppError {\n  constructor(message, errors = []) {\n    super(message, 400, 'VALIDATION_ERROR');\n    this.errors = errors;\n  }\n}\n\nclass AuthError extends AppError {\n  constructor(message = 'Not authenticated') {\n    super(message, 401, 'AUTH_ERROR');\n  }\n}\n\nclass ForbiddenError extends AppError {\n  constructor(message = 'Insufficient permissions') {\n    super(message, 403, 'FORBIDDEN');\n  }\n}\n\n// Wrap async route handlers to catch rejected promises\nconst asyncHandler = (fn) => (req, res, next) => {\n  Promise.resolve(fn(req, res, next)).catch(next);\n};\n\n// Centralized error handler\nfunction errorHandler(err, req, res, next) {\n  // Log all errors\n  console.error(\`[ERROR] \${err.code || 'UNKNOWN'}: \${err.message}\`);\n  if (!err.isOperational) {\n    console.error(err.stack);\n  }\n\n  // Operational errors: send details to client\n  if (err.isOperational) {\n    const response = {\n      error: {\n        code: err.code,\n        message: err.message,\n      }\n    };\n    if (err.errors) response.error.details = err.errors;\n    return res.status(err.statusCode).json(response);\n  }\n\n  // Programming errors: generic message\n  res.status(500).json({\n    error: {\n      code: 'INTERNAL_ERROR',\n      message: 'An unexpected error occurred',\n    }\n  });\n}\n\nmodule.exports = { AppError, NotFoundError, ValidationError, AuthError, ForbiddenError, asyncHandler, errorHandler };`,
    solutionExplanation: 'Centralized error handling separates error creation from error response formatting. The AppError class hierarchy lets route handlers throw meaningful errors (throw new NotFoundError("User")) without worrying about HTTP response formatting. The isOperational flag distinguishes expected errors (user not found, invalid input) from unexpected bugs (null pointer, network failure). Operational errors send details to the client; programming errors send a generic message to avoid leaking internals. asyncHandler wraps async functions so rejected promises automatically call next(err) instead of crashing.',
    hints: ['Create a base error class with statusCode and isOperational flag. Subclasses set specific status codes.', 'The error handler middleware has 4 parameters (err, req, res, next). Only send error details for operational errors.'],
    testCases: [
      { input: 'throw new NotFoundError("User")', expectedOutput: '404 { error: { code: "NOT_FOUND", message: "User not found" } }', description: 'NotFoundError returns 404' },
      { input: 'throw new ValidationError("Invalid", [{field: "email"}])', expectedOutput: '400 with error details', description: 'ValidationError returns 400 with details' },
      { input: 'Unexpected TypeError thrown', expectedOutput: '500 generic error, no stack trace', description: 'Programming errors return 500 safely' }
    ],
    tags: ['error-handling', 'express', 'middleware', 'architecture'],
    estimatedMinutes: 15,
  },
  {
    id: 'be-007',
    category: 'backend',
    subcategory: 'data-storage',
    title: 'Database Indexing Trade-offs',
    difficulty: 3,
    type: 'EXPLAIN',
    description: 'Explain database indexing: what indexes are, how they work (B-tree structure), when to add them, composite index ordering, and their costs. Include guidance on how to identify missing indexes from slow query analysis.',
    solution: 'Indexes are data structures (typically B-trees) that maintain sorted pointers to table rows, enabling O(log n) lookups instead of O(n) full table scans.\n\nWhen to add indexes:\n- Columns frequently used in WHERE clauses\n- Columns used in JOIN conditions\n- Columns used in ORDER BY\n- Foreign key columns\n- Columns with high cardinality (many unique values)\n\nWhen NOT to index:\n- Small tables (full scan is faster than index lookup)\n- Columns with low cardinality (boolean, status with 3 values)\n- Columns rarely used in queries\n- Tables with heavy write workloads where read performance is not critical\n\nComposite index ordering matters. An index on (A, B, C) can serve queries filtering on A, on A+B, or on A+B+C, but NOT on B alone or C alone. Put the most selective (highest cardinality) column first, and equality conditions before range conditions.\n\nCosts of indexes:\n- Write overhead: every INSERT, UPDATE, DELETE must update the index\n- Storage space: each index is a separate data structure on disk\n- Maintenance overhead: index fragmentation requires periodic rebuilding\n- Too many indexes slow down writes significantly\n\nIdentifying missing indexes:\n- EXPLAIN ANALYZE on slow queries: look for Seq Scan on large tables\n- Monitor pg_stat_user_tables for sequential scan counts\n- Check pg_stat_user_indexes for unused indexes to remove\n- Look for high-cost sort operations that could use an index',
    solutionExplanation: 'This question tests practical database knowledge. The key insight is that indexes are not free — they trade write performance and storage for read performance. Senior engineers understand composite index column ordering (leftmost prefix rule), can read query execution plans, and know when indexes hurt more than they help. The best answer demonstrates thinking about the whole system: read/write ratio, data distribution, and query patterns.',
    hints: ['Think about indexes as a sorted phone book. You can quickly look up by last name (first column), but not by first name alone if the book is sorted by last name first.', 'Every index must be updated on writes. A table with 10 indexes means each INSERT updates 10 data structures.'],
    tags: ['database', 'indexing', 'performance', 'b-tree', 'query-optimization'],
    estimatedMinutes: 10,
  },
  {
    id: 'be-008',
    category: 'backend',
    subcategory: 'scalability',
    title: 'Horizontal vs Vertical Scaling',
    difficulty: 4,
    type: 'EXPLAIN',
    description: 'Compare horizontal scaling (adding more machines) vs vertical scaling (adding more resources to a machine). Discuss trade-offs, when each is appropriate, and architectural implications of choosing horizontal scaling for a web application.',
    solution: 'Vertical Scaling (Scale Up): Add more CPU, RAM, or disk to existing machine.\nPros: Simple, no code changes, no distributed system complexity, consistent performance.\nCons: Hardware limits (you cannot infinitely upgrade a single machine), single point of failure, expensive at high end, downtime during upgrades.\nBest for: Databases (until you need sharding), early-stage applications, workloads that are hard to parallelize.\n\nHorizontal Scaling (Scale Out): Add more machines behind a load balancer.\nPros: Near-infinite capacity, better fault tolerance, commodity hardware is cheaper, can scale elastically.\nCons: Requires stateless application design, distributed system complexity (data consistency, network partitions), session management challenges, more complex deployment.\nBest for: Stateless web servers, microservices, read-heavy workloads.\n\nArchitectural Implications of Horizontal Scaling:\n1. Statelessness: Application servers must not store session data in memory. Use external stores (Redis).\n2. Shared storage: File uploads cannot stay on one server. Use S3 or distributed file storage.\n3. Database: Becomes the bottleneck. Solutions: read replicas, connection pooling, caching layer, eventually sharding.\n4. Caching: In-memory cache per server is wasted. Use distributed cache (Redis cluster).\n5. Background jobs: Need a distributed job queue (Bull, SQS) instead of in-process cron.\n6. Deployment: Need rolling deployments, health checks, service discovery.\n7. Monitoring: Must aggregate logs and metrics across instances.\n\nThe right answer is usually: start vertical, go horizontal when vertical limits are reached or fault tolerance requirements demand it.',
    solutionExplanation: 'This question reveals systems thinking maturity. Junior engineers default to "just add more servers." Senior engineers understand that horizontal scaling introduces distributed systems complexity that should be adopted deliberately. The strongest answers discuss specific architectural constraints (statelessness, session management, shared storage) and acknowledge that vertical scaling is simpler and often sufficient for longer than expected.',
    hints: ['Horizontal scaling is not just "add more servers." It forces your architecture to be stateless, which has cascading implications for sessions, file storage, caching, and background jobs.', 'Consider the database separately. Application servers scale horizontally easily. Databases are much harder to scale horizontally (sharding is complex).'],
    tags: ['scalability', 'architecture', 'horizontal-scaling', 'vertical-scaling', 'distributed-systems'],
    estimatedMinutes: 12,
  },
  {
    id: 'be-009',
    category: 'backend',
    subcategory: 'architecture-patterns',
    title: 'Layered Architecture Design',
    difficulty: 4,
    type: 'DESIGN',
    description: 'Design the folder structure and layer boundaries for an Express.js API following layered architecture. Explain the responsibility of each layer, how data flows between layers, and the dependency rules. Include how you would handle cross-cutting concerns like logging, validation, and error handling.',
    solution: 'Layered Architecture for Express API:\n\n/src\n  /routes          - Route definitions, parameter parsing, middleware composition\n  /controllers     - Request/response handling, input validation, delegates to services\n  /services        - Business logic, orchestrates repositories, enforces rules\n  /repositories    - Data access, database queries, abstracts storage\n  /models          - Data definitions, schemas, types\n  /middleware      - Cross-cutting: auth, logging, error handling, rate limiting\n  /utils           - Pure utility functions\n  /config          - Configuration management, environment variables\n  /types           - TypeScript type definitions\n\nData Flow: Route -> Controller -> Service -> Repository -> Database\n\nDependency Rule: Each layer only depends on the layer directly below it. Controllers never call repositories directly. Services never construct HTTP responses.\n\nLayer Responsibilities:\n- Routes: URL pattern matching, middleware chain assembly. No logic.\n- Controllers: Parse req params/body/query, validate input shape, call service, format HTTP response. No business logic.\n- Services: All business rules, validation of business invariants, orchestrate multiple repositories, emit events. No HTTP awareness.\n- Repositories: Database queries only. No business logic. Return domain objects.\n\nCross-cutting Concerns:\n- Logging: Middleware for request logging, service-level logging for business events\n- Validation: Joi/Zod schemas in controllers for input, business validation in services\n- Error Handling: Centralized error middleware, custom error classes thrown from any layer\n- Authentication: Middleware applied at route level\n- Caching: Service level (cache before repository call) or repository level',
    solutionExplanation: 'Layered architecture enforces separation of concerns by restricting which layer can call which. The key principle is unidirectional dependency: routes depend on controllers, controllers on services, services on repositories. This makes each layer independently testable (mock the layer below), replaceable (swap PostgreSQL for MongoDB by only changing the repository), and understandable (each file has one clear responsibility). Cross-cutting concerns use middleware and are configured at the composition root, not scattered through business logic.',
    hints: ['Think about what each layer should NOT know. Controllers should not know which database is used. Services should not know about HTTP status codes.', 'The key test: can you unit test a service without starting an HTTP server? Can you unit test a controller without a real database? If yes, your layers are properly separated.'],
    tags: ['architecture', 'layered-architecture', 'separation-of-concerns', 'express', 'design-patterns'],
    estimatedMinutes: 15,
  },
  {
    id: 'be-010',
    category: 'backend',
    subcategory: 'observability',
    title: 'Structured Logging Strategy',
    difficulty: 3,
    type: 'EXPLAIN',
    description: 'Design a logging strategy for a production Node.js application. Cover log levels, structured logging format, what to log vs what not to log, correlation IDs for request tracing, and how to make logs useful for debugging production issues.',
    solution: 'Log Levels:\n- ERROR: Unexpected failures requiring immediate attention (unhandled exceptions, service unavailable)\n- WARN: Unexpected but recoverable situations (deprecated API usage, retry succeeded, rate limit approaching)\n- INFO: Significant business events (user registered, order placed, payment processed)\n- DEBUG: Detailed diagnostic information (function entry/exit, variable values). Disabled in production.\n\nStructured Logging Format (JSON):\n{"timestamp":"2024-01-15T10:30:00Z","level":"info","message":"Order placed","service":"order-service","correlationId":"abc-123","userId":"user-456","orderId":"ord-789","amount":99.99,"duration":145}\n\nNever plain text: console.log("Order placed for user " + userId). Always structured JSON that can be parsed and queried.\n\nWhat to Log:\n- Request start and end (with duration, status code, path)\n- Business events (user actions, state transitions)\n- External service calls (with duration, success/failure)\n- Errors with full context (but not stack traces for operational errors)\n- Security events (login attempts, permission denied)\n\nWhat NOT to Log:\n- Passwords, tokens, API keys, credit card numbers\n- PII without redaction (full names, emails in debug logs)\n- High-frequency events in hot loops (will flood and cost money)\n- Health check requests (noise)\n\nCorrelation IDs: Generate a unique ID per incoming request (or use X-Request-ID header). Pass it through all service calls and include it in every log entry. This lets you trace a single user request across multiple services and log lines.\n\nMaking Logs Useful:\n- Use a log aggregation tool (ELK, Datadog, CloudWatch)\n- Add contextual fields, not just messages\n- Set up alerts on ERROR rate spikes\n- Create dashboards for key business metrics from logs\n- Ensure all team members can search and query logs',
    solutionExplanation: 'Production logging is not console.log. Senior engineers think about logs as a queryable data stream. Structured JSON logs enable filtering by any field (show me all ERROR logs for user X in the last hour). Correlation IDs are essential in microservices to trace a request across services. The most common mistake is logging too much noise or too little context — both make debugging harder.',
    hints: ['Think about being woken up at 3 AM. What information in the logs would help you diagnose the issue quickly? That is what you should be logging.', 'Structured (JSON) logs vs plain text: can you programmatically query "show me all requests that took over 500ms for the orders service"? With structured logs, yes.'],
    tags: ['logging', 'observability', 'production', 'debugging', 'correlation-id'],
    estimatedMinutes: 10,
  }
];
